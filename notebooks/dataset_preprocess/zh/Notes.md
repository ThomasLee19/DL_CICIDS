# CICIDS2017数据预处理脚本详解

这个预处理脚本设计用于处理CICIDS2017网络流量异常检测数据集。让我为您解释其整体逻辑和具体用途：

## 整体逻辑

该脚本遵循"先预处理后合并"的策略，主要分为三个核心部分：
1. 单文件预处理函数
2. 批量处理所有文件的函数
3. 合并已处理文件的函数

## 具体模块解析

### 1. 预处理单个文件函数 (`preprocess_cicids_file`)

这个函数接收一个CSV文件路径，执行以下预处理步骤：

- **加载文件**：尝试多种编码方式（utf-8, latin1等）加载CSV文件，提高兼容性
- **添加数据源标记**：
  - 添加`Day`列（Monday到Friday）
  - 添加`Scenario`列标记攻击类型（WebAttacks, DDoS等）
  - 这些标记对于后续分析不同攻击类型的特征非常重要

- **统一列名格式**：移除列名中的空格，确保所有文件使用统一的列名格式

- **处理缺失值**：
  - 检测并报告缺失值
  - 使用中位数填充缺失值，特别是"Flow Bytes/s"列

- **处理无穷值**：
  - 检测并报告无穷值(inf, -inf)
  - 用中位数替换无穷值，确保数值特征的有效性

- **统一标签列**：
  - 处理标签列名不一致问题（'Label'和' Label'）
  - 统一标签格式（去除空格、转为大写）
  - 显示标签分布情况

- **异常值检测**：
  - 使用IQR方法（四分位距）计算每个列的异常值数量
  - 报告但不删除异常值，保留数据完整性

### 2. 批量预处理函数 (`preprocess_all_cicids_files`)

这个函数用于批量处理文件夹中的所有CSV文件：

- 自动查找所有CSV文件
- 对每个文件调用单文件预处理函数
- 维护一个字典，存储所有处理后的数据框
- 可选择保存中间处理结果，方便检查和调试

### 3. 合并函数 (`merge_preprocessed_files`)

当所有文件都预处理完成后：

- 将所有预处理后的数据框合并成一个
- 显示合并后的数据形状和标签分布
- 可选择保存最终合并结果

## 具体用途

此脚本的具体用途包括：

1. **数据质量控制**：
   - 处理缺失值、无穷值等数据质量问题
   - 确保所有文件使用统一的格式和列名

2. **数据标准化**：
   - 统一标签格式，解决标签列不一致问题
   - 标记数据来源，方便后续分析

3. **数据探索**：
   - 提供每个文件的标签分布
   - 报告各特征的异常值情况
   - 为后续的特征工程提供基础

4. **数据整合**：
   - 以标准化方式合并所有文件
   - 生成可用于机器学习模型的完整数据集

通过这个预处理脚本，您可以将CICIDS2017的八个CSV文件转换为一个经过清洗、标准化的数据集，保留了每天的攻击信息，同时解决了各种数据质量问题，为后续的深度学习异常检测模型训练做好准备。

这种"先预处理后合并"的方法不仅能减轻内存压力，还能更好地处理各文件特有的问题，同时保持预处理的一致性。